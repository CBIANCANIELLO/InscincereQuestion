{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "from tqdm import tqdm_notebook\n",
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "dc0c513075393d027bad14b0d3fcfa7b4ebfea8e"
   },
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "mispell_dict = {\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\",\n",
    "\"tryin'\":\"trying\"}\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "59f6ad6b0237e15585287b42f9cda364c3bfdf07"
   },
   "outputs": [],
   "source": [
    "lm = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f16f676a01eaab2ff9c0a76feb94626be0ffbf94"
   },
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "43ce3c09b14e74bc39f5176db6061c651280f88d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../input/embeddings'),\n",
       " WindowsPath('../input/glove.840B.300d'),\n",
       " WindowsPath('../input/sample_submission.csv'),\n",
       " WindowsPath('../input/test.csv'),\n",
       " WindowsPath('../input/train.csv')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if lm: path = Path('../input'); \n",
    "list(path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "091feb4a29e9dee4a5d7504f410df3fd91f4904a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xw5735\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(path/'train.csv')\n",
    "test_df = pd.read_csv(path/'test.csv')\n",
    "allText_df = train_df.copy().append(test_df.copy())\n",
    "\n",
    "allText_df[\"question_text\"] = allText_df[\"question_text\"].apply(lambda x: x.lower())\n",
    "allText_df[\"question_text\"] = allText_df[\"question_text\"].apply(lambda x: clean_text(x))\n",
    "allText_df[\"question_text\"] = allText_df[\"question_text\"].apply(lambda x: clean_numbers(x))\n",
    "allText_df[\"question_text\"] = allText_df[\"question_text\"].apply(lambda x: replace_typical_misspell(x))\n",
    "\n",
    "#train_df[\"question_text\"] = train_df[\"question_text\"].apply(lambda x: x.lower())\n",
    "#train_df[\"question_text\"] = train_df[\"question_text\"].apply(lambda x: clean_text(x))\n",
    "#train_df[\"question_text\"] = train_df[\"question_text\"].apply(lambda x: clean_numbers(x))\n",
    "#train_df[\"question_text\"] = train_df[\"question_text\"].apply(lambda x: replace_typical_misspell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "0edef300616d3ef855113bd93c5a561a10a56a6a"
   },
   "outputs": [],
   "source": [
    "if lm:\n",
    "    bs = 48\n",
    "    data_lm = (TextList.from_df(allText_df, path, cols='question_text')\n",
    "                .split_by_rand_pct(0.1)\n",
    "                .label_for_lm()           \n",
    "                .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d302385a978d5bf660f3556e3d539b4a1a2f250c"
   },
   "outputs": [],
   "source": [
    "if lm:\n",
    "    data_lm.save('tmp_lm')\n",
    "    #data_lm = load_data('.','tmp_lm', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data(path,'tmp_lm', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "1ad8e87b519aafd967bc491abf918f77919da596"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mountain bike by just changing the tyres ? xxbos is gaza slowly becoming auschwitz , dachau or xxunk for palestinians ? xxbos why does quora automatically ban conservative opinions when reported , but does not do the same for liberal views ? xxbos is it crazy if i wash or wipe my groceries off ? germs are everywhere . xxbos is there such a thing as dressing moderately , and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>are the chances of a multiverse ? xxbos why do doctors hate earphones ? xxbos what would you do if you realize that you were worse at something than you thought ? xxbos why xxunk were not found in city ? xxbos what should one expect from neet if they ’ ve not got good rank in all india mock test ? xxbos earth ’ s magnetic field has been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i do when i don ’ t know what i am passionate about due to depression ? xxbos what , as a white person with liberal leanings , makes you feel you deserve to live in xxrep 4 # ? it seems you have no purpose other than to apologize for existing . xxbos how can i help a friend who is suffering from a nervous breakdown ? xxbos how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>m great and when i feel bad my whole world is hell . what is this called and how do i go about seeing things more realistically and stopping the extremes ? xxbos are there good job oppurtunities for chip designing ? xxbos what job can an uneducated person do at a hospital ? xxbos what insect bite causes pus ? xxbos how can i seduce a dog ? xxbos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>? xxbos how can i get the neighbor ' s dog to stop barking ? xxbos i am currently a gis analyst and my employer wants me to get the xxunk certification . is the xxunk certification worth it ? how important is the xxunk ? xxbos why does my dog keeps licking her breasts ? xxbos what does “ # # - second spot ” mean in the advertising</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#data_lm.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "max_features = 60000\n",
    "embedding_path = \"../input/embeddings/glove.840B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore'))\n",
    "# all_embs = np.stack(embedding_index.values())\n",
    "# emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std = -0.005838499, 0.48782197\n",
    "word_index = data_lm.vocab.stoi\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#embedding_matrix\n",
    "#help(nn.Embedding.from_pretrained)\n",
    "class EmbeddingDot(nn.Module):\n",
    "    def __init__(self, n_users, n_movies):\n",
    "        super().__init__()\n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_movies, n_factors)\n",
    "        self.u.weight.data.uniform_(0,0.05)\n",
    "        self.m.weight.data.uniform_(0,0.05)\n",
    "        \n",
    "    def forward(self, cats, conts):\n",
    "        users,movies = cats[:,0],cats[:,1]\n",
    "        u,m = self.u(users),self.m(movies)\n",
    "        return (u*m).sum(1)\n",
    "    \n",
    "wd=1e-5\n",
    "model = EmbeddingDot(n_users, n_movies).cuda()\n",
    "opt = optim.SGD(model.parameters(), 1e-1, weight_decay=wd, momentum=0.9)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4835252db30dc641d407550ca7a7c45b98dd123c"
   },
   "outputs": [],
   "source": [
    "if lm:\n",
    "    learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3)\n",
    "    learn.unfreeze()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "5a2221a979a58caee8448ba1d1512130edcc9a4a"
   },
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa881c6247cbddec0abacc39a1dede7454bc95fe"
   },
   "outputs": [],
   "source": [
    "if lm: learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b5747c05961179cd1675c80865ddb67116283042"
   },
   "outputs": [],
   "source": [
    "if lm: learn.save('language_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1a5fad2ffc24a1ff28ba9380d6e90dfa83aa1df"
   },
   "outputs": [],
   "source": [
    "if lm: learn.save_encoder('lm_encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b6ceb4d5d65f537071fcdc4ea65b2c1f7b38d6bf"
   },
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81713f6e9b655613508501e6842a332ac2e31dbc"
   },
   "outputs": [],
   "source": [
    "class TextClasDataBunch(TextDataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs=64,val_bs=None, pad_idx=1, pad_first=True,\n",
    "               device=None,no_check:bool=False, shuffle=[True, True, False],backwards=False, **kwargs) -> DataBunch:\n",
    "        \"Function that transform the `datasets` in a `DataBunch` for classification.\"\n",
    "        datasets = [train_ds, valid_ds, test_ds]\n",
    "        collate_fn = partial(pad_collate, pad_idx=pad_idx, pad_first=pad_first)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs//2, sampler=train_sampler, drop_last=True, **kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        dataloaders.append(DataLoader(datasets[1], batch_size=bs, **kwargs))\n",
    "        dataloaders.append(DataLoader(datasets[2], batch_size=bs, **kwargs))\n",
    "        return cls(*dataloaders, path=path, collate_fn=collate_fn)\n",
    "    \n",
    "TextList._bunch = TextClasDataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "path = Path('../input'); list(path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8557e86b503d381273575ea5bbead1ec478bb1c0"
   },
   "outputs": [],
   "source": [
    "if lm:\n",
    "    train_df = pd.read_csv(path/'train.csv').sample(frac=0.3, random_state=42)\n",
    "else:\n",
    "    train_df = pd.read_csv(path/'train.csv').sample(frac=0.9, random_state=42)\n",
    "\n",
    "train_df[\"question_text\"] = train_df[\"question_text\"].apply(lambda x: x.lower())\n",
    "train_df[\"question_text\"] = train_df[\"question_text\"].apply(lambda x: clean_text(x))\n",
    "train_df[\"question_text\"] = train_df[\"question_text\"].apply(lambda x: clean_numbers(x))\n",
    "train_df[\"question_text\"] = train_df[\"question_text\"].apply(lambda x: replace_typical_misspell(x))\n",
    "#train0 = train_df[train_df.target==0].sample(n=100000, random_state=42)\n",
    "#train1 = train_df[train_df.target==1].sample(n=100000, random_state=42, replace=True)\n",
    "#train = pd.concat((train0, train1)); len(train)\n",
    "#train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aee9a731749532d1c9590139a5c64af39f85b034"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(path/'test.csv')\n",
    "test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: x.lower())\n",
    "test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: clean_text(x))\n",
    "test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: clean_numbers(x))\n",
    "test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: replace_typical_misspell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aee9a731749532d1c9590139a5c64af39f85b034"
   },
   "outputs": [],
   "source": [
    "test = TextList.from_df(test_df, path, cols='question_text')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "2e74705319e2f92636a7c16ae8c4b65e18d2913d"
   },
   "source": [
    "train['weights'] = 0\n",
    "train.loc[train.target==1, 'weights'] = 0.06187\n",
    "train.loc[train.target==0, 'weights'] = 1-0.06187"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "fcc786d532650ed37e86660f0fcc6b84e9b20d81"
   },
   "source": [
    "valid = train.sample(frac=0.1, weights=train.weights.values, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e5a7e9110d2edd24e5c350b9ca4ccc077171073"
   },
   "outputs": [],
   "source": [
    "if lm:\n",
    "    data = (TextList.from_df(train_df, path, cols='question_text', vocab=data_lm.vocab)\n",
    "                    .split_by_rand_pct(0.1)\n",
    "                    .label_from_df(cols=2)\n",
    "                    .add_test(test)\n",
    "                    .databunch(path='.')) \n",
    "else:\n",
    "    data = (TextList.from_df(train_df, path, cols='question_text')\n",
    "                .split_by_rand_pct(0.1)\n",
    "                .label_from_df(cols=2)\n",
    "                .add_test(test)\n",
    "                .databunch(path='.')) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "7e5a7e9110d2edd24e5c350b9ca4ccc077171073"
   },
   "source": [
    "data.save()\n",
    "data = TextDataBunch.load('.')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "f59dfa90ed8d9439b1cb02586de0be18a61674cb"
   },
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a77d92a1042dcc93f18104283481aae191573c38"
   },
   "outputs": [],
   "source": [
    "f_score = FBeta(beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4be9553ff662ba500dfac18d83991cfb70c9cf61"
   },
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data,arch=AWD_LSTM, drop_mult=0.5, metrics=[accuracy, f_score])\n",
    "if lm: learn.load_encoder('lm_encoder')\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a859e4e83424f44c0c82ff1d7c90d3cd694869b"
   },
   "outputs": [],
   "source": [
    "gc.collect();"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "dec251866954f2934b5316070a81045eda33b44c"
   },
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57a5a8ff96fe629d48153ce461d8a9f73b5f012a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "9ad70ed0eadd99e4a1e7121000e561f3d44996e9"
   },
   "source": [
    "learn.save('first')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "9c68f2821a7cb6171d7768412eaa2093d3c8221e"
   },
   "source": [
    "learn.load('first');"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "02ae7221fdfe1925422d5070970266a89a2f8e85"
   },
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "f3cd8df4cc6ceff7ee2244b722654401b714c1c8"
   },
   "source": [
    "learn.save('second')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "992a108e5f441edb4a1eb77ed4c8155e3af5ff6d"
   },
   "source": [
    "learn.load('second');"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "8bc9c6bba52b1cdaa6fedcec8b43fe871bb8f74b"
   },
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "bc2d5b272e98753a98639c6464889280acc462c1"
   },
   "source": [
    "learn.save('third')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "cf4ff0d1ee907889bffc029849441d77b3bafc47"
   },
   "source": [
    "learn.load('third');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b17b36aebe9e1be91389c30db94293b79206b51"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "e201769d95486a2aef85f553ef5cf648702043b8"
   },
   "source": [
    "learn.save('final')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "59e76cf4ad73c67b63afca627e3cd439c9fed287"
   },
   "source": [
    "learn.load('final');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea467e08ba405c40b2941fafa6aa1f90057a3455"
   },
   "outputs": [],
   "source": [
    "preds = learn.get_preds(DatasetType.Valid)\n",
    "proba = to_np(preds[0][:,1])\n",
    "ytrue = to_np(preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04166b453254abc6083743f2f887f1c902b9f567"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "def threshold_search(y_true, y_proba, plot=False):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    thresholds = np.append(thresholds, 1.001) \n",
    "    F = 2 / (1/precision + 1/recall)\n",
    "    best_score = np.max(F)\n",
    "    best_th = thresholds[np.argmax(F)]\n",
    "    if plot:\n",
    "        plt.plot(thresholds, F, '-b')\n",
    "        plt.plot([best_th], [best_score], '*r')\n",
    "        plt.show()\n",
    "    search_result = {'threshold': best_th , 'f1': best_score}\n",
    "    return search_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67261e5c0b8cf51dd512b7dd4afd71d1373365cf"
   },
   "outputs": [],
   "source": [
    "thr = threshold_search(ytrue, proba, plot=True); thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f307bb6844d4384bc43215112385cfe3f31f3967"
   },
   "outputs": [],
   "source": [
    "preds = learn.get_preds(DatasetType.Test)\n",
    "proba = to_np(preds[0][:,1])\n",
    "predsC = (proba > thr['threshold']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd20f0c905d874a57a6aeabd9168a65dee7792ed"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "sub.prediction = predsC\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d88a986e7331419cb906ea3e77614c002d1db82b"
   },
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b2ba3257242527988d478875e740d2760559a0ca"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
